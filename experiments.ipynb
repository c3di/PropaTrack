{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a24eb56a7c47fcd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Experiments\n",
    "### Notebook to run experiments on the data supplied by the chair of functional materials at Saarland University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70237172f5fc33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 1\n",
    "### Run RAFT optical flow model on the data\n",
    "<font size=\"5\"> \n",
    "In this experiment we will run the RAFT optical flow model on the data to see how well it performs compared to classical optical flow methods.\n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "RAFT tracks the reaction front quite well. The reaction front is visible in the optical flow images but there is also a lot of noise.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c345de85fb8145",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from raft.utils import get_video_frames, plot_frames, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe78f1d47b1f36",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_path = \"videos/double_c_shape.mp4\"\n",
    "frames = get_video_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f8cbec9819aa6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the numbers in frames to see different images.\n",
    "img_batch = torch.stack([frames[50], frames[51]])\n",
    "plot_frames(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9a9e2fcb866d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.models.optical_flow.raft import Raft_Large_Weights\n",
    "\n",
    "model = raft_large(weights=Raft_Large_Weights.C_T_V2)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1cb202f1496af2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1_batch: torch.Tensor = preprocess(torch.stack([frames[130], frames[220]]))\n",
    "img2_batch: torch.Tensor = preprocess(torch.stack([frames[131], frames[221]]))\n",
    "\n",
    "plot_frames(img1_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d9556dadca2ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4e2c8fc9adcf3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_flows: torch.Tensor = model(img1_batch, img2_batch)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69928f67bbbff1f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import flow_to_image\n",
    "flow_images = flow_to_image(predicted_flows)\n",
    "\n",
    "# The images have been mapped into [-1, 1] but for plotting we want them in [0, 1]\n",
    "img1_batch = (img1_batch + 1.) / 2.\n",
    "\n",
    "grid = [[img1, flow_img] for (img1, flow_img) in zip(img1_batch, flow_images)]\n",
    "plot_frames(grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8ce6a",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "### Obtain reaction front from difference between frames\n",
    "<font size=\"5\"> \n",
    "In this experiment we will see how well we can obtain the reaction front by simply taking the difference between frames. We set pixels with very small and large differences between two frames to zero, as they seem to be noise. We also binarize the image to make the front more visible. For further denoising we apply a morphological operation called <i>Opening</i>, which removes all white spots smaller than a certain size. Mathematical morphology in the context of image processing deals with analysing and modifying structures in an image based on their geometrical properties. \n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "The reaction front is actually quite visible in the difference between frames. This is a very simple method to obtain the reaction front.  The method also seems to outperform the old optical flow method in terms of noise and also speed.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cabb1949635f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from tqdm import tqdm\n",
    "from utils.video_handling import get_video_frames\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9de882a17a2f97",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "footprint = morphology.disk(3)\n",
    "\n",
    "for video_name in os.listdir(\"videos/\"): \n",
    "    print(f\"Generating flow for {video_name}\")\n",
    "    video_path = \"videos/\" + video_name\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    frames = get_video_frames(video_path)\n",
    "    dir_name = \"results/experiment2/\"\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    video_writer = cv2.VideoWriter(dir_name + video_name, fourcc, 10.0, (width, height))\n",
    "    for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "        # Calculate the difference between two frames.\n",
    "        flow = frames[i+1] - frames[i]\n",
    "        flow = flow.astype(np.uint8)\n",
    "        \n",
    "        # Threshold and binarize the image.\n",
    "        flow[flow > 180] = 0\n",
    "        flow[flow < 20] = 0\n",
    "        flow[flow > 0] = 255\n",
    "        \n",
    "        # Apply morphological opening.\n",
    "        flow = morphology.opening(flow, footprint)\n",
    "        flow = cv2.cvtColor(flow, cv2.COLOR_GRAY2BGR)\n",
    "        video_writer.write(flow)\n",
    "        \n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e62ffc9c4bbb9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 3\n",
    "### Track the reaction fronts through the frames\n",
    "<font size=\"5\"> \n",
    "In this experiment we will try to track the reaction front and its offsprings throughout the frames. Since the images will be binarized we can use local connectivity of the pixels as a criterion for tracking. \n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "Segmenting the reaction front and it's offspring works quite good on a per frame basis, but it's difficult to track the different fronts throughout the frames.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551152f2f46d43b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology, measure\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils.video_handling import get_video_frames\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388951942084d30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "footprint = morphology.disk(3)\n",
    "\n",
    "cmap = plt.get_cmap('tab20')\n",
    "props_old = None\n",
    "\n",
    "for video_name in os.listdir(\"videos/\"): \n",
    "    print(f\"Generating flow for {video_name}\")\n",
    "    video_path = \"videos/\" + video_name\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    frames = get_video_frames(video_path)\n",
    "    video_writer = cv2.VideoWriter(\"results/experiment3/\" + video_name, fourcc, 10.0, (width, height))\n",
    "    for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "        # Calculate the difference between two frames.\n",
    "        flow = frames[i+1] - frames[i]\n",
    "        flow = flow.astype(np.uint8)\n",
    "        \n",
    "        # Threshold and binarize the image.\n",
    "        flow[flow > 180] = 0\n",
    "        flow[flow < 20] = 0\n",
    "        flow[flow > 0] = 255\n",
    "        \n",
    "        # Apply morphological opening.\n",
    "        flow = morphology.opening(flow, footprint)\n",
    "        \n",
    "        # Label the connected components.\n",
    "        labeled_flow, num_labels = measure.label(flow, return_num=True)\n",
    "        labeled_flow = cv2.cvtColor(labeled_flow.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "        flow = cv2.cvtColor(flow, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        for j in range(1, num_labels):\n",
    "            color = cmap(j)\n",
    "            color_array = (np.array(color[:-1]) * 255).astype(np.uint8)\n",
    "            flow = np.where(labeled_flow == j, color_array, flow)\n",
    "            \n",
    "        video_writer.write(flow)\n",
    "    \n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad77b56f4d1076",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 4\n",
    "### Apply optical flow to the binarized video frames\n",
    "<font size=\"5\"> \n",
    "In this experiment we will apply an optical flow algorithm to the binarized videos to get a vector field describing the speed of the reaction front at each point in time.\n",
    "\n",
    "04.05.2024:\n",
    "- Try adding skeletonization before calculating the optical flow and use opencv's calcOpticalFlowFarneback function.\n",
    "\n",
    "05.05.2024:\n",
    "- I tried playing around with the parameters of the algorithm like *poly_sigma* and *poly_n*.\n",
    "</font>\n",
    "<br><br>\n",
    "\n",
    "### Hypothesis\n",
    "<font size=\"5\">\n",
    "Since the frames are almost noise free I expect the optical flow algorithm to perform quite well on the data.\n",
    "</font>\n",
    "<br><br>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "The algorithm fails spectacularily, seemingly tracking the reaction fronts but also causing seemingly random splashes of greytones.\n",
    "\n",
    "04.05.2024:\n",
    "- After applying skeletonization there are no splashes anymore, but there still is noise and the flow seems to be too thick.\n",
    "\n",
    "05.05.2024:\n",
    "- Modifying the parameters doesn't improve the result.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4214c826a351e81",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils.video_handling import get_video_frames\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5720011bce3579c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "footprint = morphology.disk(3)\n",
    "\n",
    "cmap = plt.get_cmap('plasma')\n",
    "props_old = None\n",
    "\n",
    "for video_name in os.listdir(\"videos/\"): \n",
    "    print(f\"Generating flow for {video_name}\")\n",
    "    video_path = \"videos/\" + video_name\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    frames = get_video_frames(video_path)\n",
    "    \n",
    "    dir_name = \"results/experiment4_farneback_poly_sigma_0_2_poly_n_3/\"\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    video_writer = cv2.VideoWriter(dir_name + video_name, fourcc, 10.0, (width, height))\n",
    "    \n",
    "    for i, _ in tqdm(enumerate(frames[1:-1])):\n",
    "        # Calculate the difference between two frames.\n",
    "        diff_flow0 = (frames[i+1] - frames[i]).astype(np.uint8)\n",
    "        diff_flow1 = (frames[i] - frames[i-1]).astype(np.uint8)\n",
    "        \n",
    "        # Threshold and binarize the image.\n",
    "        diff_flow0[diff_flow0 > 180] = 0\n",
    "        diff_flow0[diff_flow0 < 20] = 0\n",
    "        diff_flow0[diff_flow0 > 0] = 255\n",
    "        \n",
    "        diff_flow1[diff_flow1 > 180] = 0\n",
    "        diff_flow1[diff_flow1 < 20] = 0\n",
    "        diff_flow1[diff_flow1 > 0] = 255\n",
    "        \n",
    "        # Apply morphological opening.\n",
    "        diff_flow0 = morphology.opening(diff_flow0, footprint)\n",
    "        diff_flow1 = morphology.opening(diff_flow1, footprint)\n",
    "        \n",
    "        diff_flow0 = morphology.skeletonize(diff_flow0)\n",
    "        diff_flow1 = morphology.skeletonize(diff_flow1)\n",
    "        \n",
    "        diff_flow0 = np.where(diff_flow0 == 1, 255, 0).astype(np.uint8)\n",
    "        diff_flow1 = np.where(diff_flow1 == 1, 255, 0).astype(np.uint8)\n",
    "        \n",
    "        flow_field = cv2.calcOpticalFlowFarneback(diff_flow0, diff_flow1, None, 0.5, 3, 15, 3, 3, 0.2, 0)\n",
    "        \n",
    "        flow = np.sqrt(flow_field[:, :, 0]**2 + flow_field[:, :, 1]**2).astype(np.uint8)\n",
    "        flow = cv2.cvtColor(flow, cv2.COLOR_GRAY2BGR) \n",
    "                \n",
    "        video_writer.write(flow)\n",
    "        \n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107f6d6727dcd85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Experiment 5\n",
    "### Apply skeletonization to the binarized video frames\n",
    "<font size=\"5\"> \n",
    "In this experiment we will apply skeletonization to the binarized videos to get a more sharp representation of the reaction front.\n",
    "</font>\n",
    "\n",
    "### Hypothesis\n",
    "<font size=\"5\">\n",
    "Will look like the previous experiments but with thin lines instead of blobs.\n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "Hypothesis turned out to be correct, there is still some noise present which I might be able to remove with more morphological operations.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cb4aaf8fd641e",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0fb52b60bd329",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from tqdm import tqdm\n",
    "from utils.video_handling import setup_experiment\n",
    "from utils.frame_processing import front_from_frames\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8ceee842f2d95",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "footprint = morphology.disk(3)\n",
    "for video_name in os.listdir(\"videos/\"): \n",
    "    video_writer, frames = setup_experiment(video_name, \"results/experiment5_low_threshold_15/\")\n",
    "    for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "        front = front_from_frames(frames[i], frames[i+1], footprint)  \n",
    "        front = cv2.cvtColor(front, cv2.COLOR_GRAY2BGR)\n",
    "        video_writer.write(front)\n",
    "        \n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d54236e984a9e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 6\n",
    "### Plot evolution of reaction front on a single canvas\n",
    "<font size=\"5\"> \n",
    "In this experiment we will plot the reaction front at each time stept on a single canvas to get an overview over its evolution in time from a single image.\n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "Fronts are clearly visible in most images. Only the videos with low resolutions and the one with the dots yield unclear images\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53a4744913f28c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.video_handling import get_video_frames\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6ae4d69f61b9e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "footprint = morphology.disk(3)\n",
    "for video_name in os.listdir(\"videos/\"): \n",
    "    frames = get_video_frames(\"videos/\" + video_name)\n",
    "    # Initialize the front\n",
    "    h, w = frames[0].shape\n",
    "    front =  np.zeros((h, w), dtype=np.uint8)\n",
    "    for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "        front += front_from_frames(frames[i], frames[i+1], footprint)  \n",
    "    fig = plt.figure(dpi=200)\n",
    "    plt.imshow(front)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Reaction Front Progression - {}\".format(video_name))\n",
    "    result_dir = \"results/experiment6/\"\n",
    "    if not os.path.isdir(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "    plt.savefig(result_dir + video_name + \".png\")       \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb400dd012591c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 7\n",
    "### Calculate distance travelled by reaction front\n",
    "<font size=\"5\"> \n",
    "In this experiment we will calculate the distance travelled by the reaction fronts between two frames by fitting contour lines to at each timestep and calculating their distance.\n",
    "</font>\n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "Fronts are clearly visible in most images. Only the videos with low resolutions and the one with the dots yield unclear images\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55da7eaa3c49a32",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.video_handling import get_video_frames\n",
    "from utils.frame_processing import front_from_frames\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed089ce7d29c4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = get_video_frames(\"videos/double_c_shape.mp4\")\n",
    "footprint = morphology.disk(3)\n",
    "# Initialize the front\n",
    "h, w = frames[0].shape\n",
    "front =  np.zeros((h, w), dtype=np.uint8)\n",
    "fronts = []\n",
    "for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "    front = front_from_frames(frames[i], frames[i+1], footprint)\n",
    "    fronts.append(front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32758716d4e70d55",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=200)\n",
    "image = fronts[11]\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Contour Lines of Reaction Front\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c263b3a5cf13e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=\"5\">Calculate the average distance between the two fronts by determining for each pixel on front 1 the closest pixel on front 2 and then taking the average of these distances.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff090d9490f15b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "distances = cdist(np.squeeze(contours[0]), np.squeeze(contours[1]))\n",
    "print(f\"Average Distance: {np.mean(np.min(distances, axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065cf8312f59f71",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=\"5\">Now we use scipy to fit splines to the contour lines and plot them.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47c09250fd44d9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, indices_unique = np.unique(contours[0], axis=0, return_index=True)\n",
    "contour0 = contours[0][np.sort(indices_unique), :]\n",
    "\n",
    "X0 = np.squeeze(contour0)[::5, 0]\n",
    "Y0 = np.squeeze(contour0)[::5, 1]\n",
    "\n",
    "X1 = np.squeeze(contours[1])[::20, 0]\n",
    "Y1 = np.squeeze(contours[1])[::20, 1]\n",
    "\n",
    "tck0, u0 = interpolate.splprep([X0, Y0], s=1)\n",
    "tck1, u1 = interpolate.splprep([X1, Y1], s=1)\n",
    "\n",
    "out0 = np.array(interpolate.splev(u0, tck0)).T\n",
    "out1 = np.array(interpolate.splev(u1, tck1)).T\n",
    "\n",
    "tangent0 = interpolate.splev(u0, tck0, der=1)\n",
    "tangent1 = interpolate.splev(u1, tck1, der=1)\n",
    "\n",
    "normal0 = np.array([-tangent0[1], tangent0[0]]).T\n",
    "normal1 = np.array([-tangent1[1], tangent1[0]]).T\n",
    "\n",
    "normal0 = normal0 / np.linalg.norm(normal0, axis=1).reshape(-1, 1)\n",
    "normal1 = normal1 / np.linalg.norm(normal1, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa56a5fa85b0206",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "plt.imshow(image)\n",
    "plt.plot(out0[:, 0], out0[:, 1], 'y', linewidth=0.25)\n",
    "plt.plot(out1[:, 0], out1[:, 1], 'g', linewidth=0.25)\n",
    "plt.quiver(out0[:, 0], out0[:, 1], normal0[:, 0], normal0[:, 1],\n",
    "           color='r', angles='xy', scale_units='xy', scale=0.05, width=0.001)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Splines fit to Contour Lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85585d9f53eb8532",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=\"5\">Calculate the average distance between the two fronts by determining for each pixel on front 1 the closest pixel on front 2 and then taking the average of these distances. Since the splines are sparser than the original reaction front it is to be expected that the average distance is slightly larger.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c169e8ea3489f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spline0 = np.array(out0).T\n",
    "spline1 = np.array(out1).T\n",
    "distances = cdist(spline0, spline1)\n",
    "print(f\"Average Distance: {np.mean(np.min(distances, axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd40d8a1babcc32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Experiment 8\n",
    "### Fit splines at each timestep.\n",
    "<font size=\"5\"> \n",
    "In this experiment we will try to fit splines to the reaction front at every timestep and evaluate how well the splines fit the front, especially when it comes to fitting small offsprings of the\n",
    "front and noise.\n",
    "\n",
    "11.05.2024:\n",
    "- Sometimes the spline does not follow the contour by connecting each point to its neighbor, but rather jumps to another point father away on the contour. I calculated the distance of each point on the contour to its neighbour in the contour array and plotted a histogram of these distances. The histogram indicates that usually the jump occurs at the last point in the array.\n",
    "- I was able to get rid of many (but not all) of these points by just removing the last point of the contour array. This is more of a hack but it works for now.\n",
    "</font>\n",
    "\n",
    "### Hypothesis\n",
    "<font size=\"5\"> \n",
    "The splines will fit the front quite well, but will have problems with small offsprings and noise.\n",
    "</font> \n",
    "\n",
    "### Results\n",
    "<font size=\"5\"> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc058e06bdefd31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.video_handling import get_video_frames\n",
    "from utils.frame_processing import front_from_frames\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage import morphology\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_video_frames(\"videos/double_c_shape.mp4\")\n",
    "footprint = morphology.disk(3)\n",
    "cmap = plt.get_cmap('tab20')\n",
    "# Initialize the front\n",
    "h, w = frames[0].shape\n",
    "blank_canvas = np.zeros((h, w), dtype=np.uint8)\n",
    "for i, _ in tqdm(enumerate(frames[:-1])):\n",
    "    front = front_from_frames(frames[i], frames[i+1], footprint)\n",
    "    contours, _ = cv2.findContours(front, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [np.squeeze(contour) for contour in contours if cv2.arcLength(contour, False) > 35]\n",
    "    \n",
    "    width = max((len(contours) + 1) * 5, 15)\n",
    "    fig, ax = plt.subplots(dpi=200,\n",
    "                           figsize=(width, 5),\n",
    "                           nrows=1,\n",
    "                           ncols=len(contours) + 1,\n",
    "                           width_ratios=[0.5] * len(contours) + [1],\n",
    "                           squeeze=False)\n",
    "    ax[-1, len(contours)].imshow(blank_canvas)\n",
    "    ax[-1, len(contours)].set_title(\"Splines fit to Contour Lines\")\n",
    "    for j, contour in enumerate(contours):\n",
    "        # The contour wraps around the image, so we only take the first half.\n",
    "        _, indices_unique = np.unique(contour, axis=0, return_index=True)\n",
    "        contour = contour[np.sort(indices_unique), :]\n",
    "        \n",
    "        steps = max(int(len(contour) * 0.05), 1)\n",
    "        length_contour = cv2.arcLength(contour, False)\n",
    "        contour = contour[::steps][:-1]\n",
    "            \n",
    "        intra_dists = np.diagonal(cdist(contour[:-1], contour[1:]))\n",
    "        ax[-1, j].bar(range(len(intra_dists)), intra_dists, color=cmap(j))\n",
    "        ax[-1, j].set_title(f\"Point distances contour {j}\")\n",
    "        X = contour[:, 0]\n",
    "        Y = contour[:, 1]\n",
    "        \n",
    "        k = 1 if len(contour) < 10 else 3\n",
    "        \n",
    "        tck, u = interpolate.splprep([X, Y], s=2, k=k)\n",
    "        out = np.array(interpolate.splev(u, tck)).T\n",
    "        ax[-1, len(contours)].plot(out[:, 0], out[:, 1], linewidth=0.25, color=cmap(j))\n",
    "    experiment_dir = \"results/experiment8_trunc/\"\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "    fig.suptitle(f\"Analysis of Frame {i}\")\n",
    "    plt.savefig(experiment_dir + f\"frame_{i}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36f6ebf7e6231629"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
